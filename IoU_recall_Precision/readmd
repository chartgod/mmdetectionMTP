# **Performance Metrics Evaluation Script**

## Description:
# This script evaluates segmentation performance metrics (IoU, F1-score, Precision, Recall) for images 
# in the `label` and `predict` directories. Results are sorted by IoU and saved to a specified output file.

## Prerequisites:
# Ensure Python and the following libraries are installed:
# - numpy
# - pillow
# - scikit-learn

## Steps to Use:

# 1. Install required libraries (if not already installed):
pip install numpy pillow scikit-learn

# 2. Prepare directories:
# Ensure the following directory structure:
# - `D:\국토위성\12\dataset\label`: Contains ground truth mask images (PNG format).
# - `D:\국토위성\12\dataset\predict`: Contains predicted mask images (PNG format).

# 3. Execute the script:
python script_name.py

# Replace `script_name.py` with the name of the Python file containing the script.

# 4. Output:
# - Results will be saved to `D:\국토위성\12\dataset\performance_results_sorted_by_iou.txt`.
# - The output file includes metrics sorted by IoU.

## Notes:
# - Ensure image filenames in `label` and `predict` directories match exactly.
# - The script automatically resizes the prediction mask to match the label mask size if necessary.
# - Errors during processing (e.g., file corruption) will be logged in the console.
